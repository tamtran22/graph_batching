{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from data.dataset import DatasetLoader, OneDDatasetLoader, OneDDatasetBuilder\n",
    "import matplotlib.pyplot as plt\n",
    "from preprocessing.batching_v2 import _get_graph_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading raw dataset\n",
    "# dataset_raw = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets'\n",
    "# )\n",
    "dataset_transformed = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_transformed'\n",
    ")\n",
    "# print(dataset_raw[0].edge_attr[1000])\n",
    "# print(dataset_transformed[0].edge_attr[1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5  6  7  8  9 10 11 12 13 14] [ 2  3  4  5  6  7  8  9 10 11 12 13 14 15 17 18 19 20 21 22 23 24 25 26\n",
      " 27 28 29 36] [0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "data = dataset_transformed[0]\n",
    "# print(data)\n",
    "graph_part = _get_graph_partition(data=data, partition=np.arange(5,15), recursive=True)\n",
    "# print(graph_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batching dataset\n",
    "# batched_dataset = dataset.batching(batch_size=5000, batch_n_times=10, recursive=True,\n",
    "#                                     sub_dir='/batched/')\n",
    "# batched_dataset = OneDDatasetLoader(\n",
    "#     root_dir='/data1/tam/downloaded_datasets_transformed',\n",
    "#     sub_dir='/batched/'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming/scaling dataset\n",
    "p_min = dataset.min(var_name='pressure', axis=None).numpy()\n",
    "p_max = dataset.max(var_name='pressure', axis=None).numpy()\n",
    "print(p_min, p_max)\n",
    "q_min = dataset.min(var_name='flowrate', axis=None).numpy()\n",
    "q_max = dataset.max(var_name='flowrate', axis=None).numpy()\n",
    "print(q_min, q_max)\n",
    "u_min = dataset.min(var_name='velocity', axis=None).numpy()\n",
    "u_max = dataset.max(var_name='velocity', axis=None).numpy()\n",
    "print(u_min, u_max)\n",
    "\n",
    "ea_min = dataset.min(var_name='edge_attr', axis=0).numpy()\n",
    "ea_max = dataset.max(var_name='edge_attr', axis=0).numpy()\n",
    "vol0_min = ea_min[-2]\n",
    "vol1_min = ea_min[-1]\n",
    "vol0_max = ea_max[-2]\n",
    "vol1_max = ea_max[-1]\n",
    "ea_min[-2] = min(vol0_min, vol1_min)\n",
    "ea_min[-1] = min(vol0_min, vol1_min)\n",
    "ea_max[-2] = max(vol0_max, vol1_max)\n",
    "ea_max[-1] = max(vol0_max, vol1_max)\n",
    "print(ea_min, ea_max)\n",
    "\n",
    "\n",
    "# p_mean = dataset.mean(var_name='pressure', axis=None).numpy()\n",
    "# p_std = dataset.std(var_name='pressure', axis=None).numpy()\n",
    "# print(p_mean, p_std)\n",
    "# q_mean = dataset.mean(var_name='flowrate', axis=None).numpy()\n",
    "# q_std = dataset.std(var_name='flowrate', axis=None).numpy()\n",
    "# print(q_mean, q_std)\n",
    "# u_mean = dataset.mean(var_name='velocity', axis=None).numpy()\n",
    "# u_std = dataset.std(var_name='velocity', axis=None).numpy()\n",
    "# print(u_mean, u_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting pressure distribution\n",
    "\n",
    "p = dataset[0].pressure.numpy()[100,:]\n",
    "\n",
    "# p = -1+2*(p-p_min)/(p_max-p_min)\n",
    "# p = (p-p_mean)/(p_std+1e-10)\n",
    "# plt.ylim(-1,1)\n",
    "# plt.hist(p, bins=1000)\n",
    "plt.plot(p)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting flowrate distribution\n",
    "\n",
    "q = dataset[0].flowrate.numpy()[50000,:]\n",
    "\n",
    "# q = (q-q_mean)/(q_std+1e-10)\n",
    "# q = -1+2*(q-q_min)/(q_max-q_min)\n",
    "# plt.xlim(-1,1)\n",
    "# plt.hist(q, bins=10)\n",
    "plt.plot(list(range(len(q))), q)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot volume\n",
    "vol0_raw = dataset_raw[0].edge_attr[:,-2].numpy()\n",
    "vol0_transformed = dataset_transformed[0].edge_attr[:,-1].numpy()\n",
    "print(vol0_raw.shape, vol0_transformed.shape)\n",
    "print(vol0_raw[1000], vol0_transformed[1000])\n",
    "\n",
    "print(vol0_raw.mean(), vol0_raw.std())\n",
    "print(vol0_transformed.mean(), vol0_transformed.std())\n",
    "\n",
    "# v_min = min(vol0.min(), vol1.min())\n",
    "# v_max = max(vol0.max(), vol1.max())\n",
    "\n",
    "# vol0 = -1+2*(vol0 - v_min)/(v_max - v_min)\n",
    "# vol1 = -1+2*(vol1 - v_min)/(v_max - v_min)\n",
    "\n",
    "# vol0 = (vol0 - vol0.mean())/(vol0.std() + 1e-10)\n",
    "# vol1 = (vol1 - vol1.mean())/(vol1.std() + 1e-10)\n",
    "\n",
    "# vol0 = (vol0 - vol0.min())/(vol0.max() + vol0.min())\n",
    "# vol1 = (vol1 - vol1.min())/(vol1.max() + vol0.min())\n",
    "\n",
    "\n",
    "# vol0 = (vol0 - np.median(vol0))/(np.percentile(vol0, 75) - np.percentile(vol0, 25))\n",
    "# vol1 = (vol1 - np.median(vol1))/(np.percentile(vol1, 75) - np.percentile(vol1, 25))\n",
    "\n",
    "# plt.plot(list(range(vol0.shape[0])), vol0, c='red')\n",
    "# plt.plot(list(range(vol0.shape[0])), vol1, c='blue')\n",
    "# plt.xlim(4350, 4450)\n",
    "# plt.ylim(-0.98,-0.88)\n",
    "\n",
    "plt.plot(vol0_raw)\n",
    "# plt.plot(vol0_transformed)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation scatter plot\n",
    "data = dataset[0]\n",
    "x = data.edge_attr.numpy()[:,6]\n",
    "# y = data.velocity.numpy()[:,50]\n",
    "y = data.flowrate.numpy().mean(axis=1)\n",
    "\n",
    "y = (y - u_min)/(u_max - u_min)\n",
    "# y = np.sign(y)*np.log(1. + np.abs(y)/1e2)\n",
    "# d = data.edge_attr.numpy()[:,1]\n",
    "# y = y / (np.square(d))\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test normalize\n",
    "from preprocessing.normalize import normalize_data_1d\n",
    "data = dataset[0]\n",
    "normed_data = normalize_data_1d(\n",
    "    data=data,\n",
    "    x_min=0, x_max=512,\n",
    "    ea_min=ea_min, ea_max=ea_max,\n",
    "    p_min=p_min, p_max=p_max,\n",
    "    u_min=u_min, u_max=u_max\n",
    ")\n",
    "print(normed_data)\n",
    "plt.plot(normed_data.flowrate_bc[1000,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate weighted loss\n",
    "data = normed_data\n",
    "diam = data.edge_attr.numpy()[:,0]\n",
    "length = data.edge_attr.numpy()[:,1]\n",
    "\n",
    "(count, bins) = np.histogram(diam, bins=5000)\n",
    "n_edge = diam.shape[0]\n",
    "\n",
    "# print(count)\n",
    "# print(bins)\n",
    "\n",
    "def weight(val : float):\n",
    "    bin_id = np.where(bins >= val)[0][0] - 1\n",
    "    weight_mean = 1. / (count[bin_id] + 1e0)\n",
    "    return weight_mean\n",
    "\n",
    "v_weight = np.vectorize(weight)\n",
    "weight_diam = v_weight(diam)\n",
    "\n",
    "\n",
    "def cal_weight(x : np.array, bins=1000) -> np.array:\n",
    "    (count, bin) = np.histogram(x, bins=bins)\n",
    "    N = x.shape[0]\n",
    "\n",
    "    def _weight(value : float):\n",
    "        _bin_id = np.where(bin >= value)[0][0] - 1\n",
    "        _weight = 1. / (count[_bin_id] + 1.)\n",
    "        return _weight\n",
    "    \n",
    "    v_weight = np.vectorize(_weight)\n",
    "\n",
    "    return v_weight(x)\n",
    "\n",
    "plt.plot(bins[:-1], count)\n",
    "plt.show()\n",
    "\n",
    "plt.plot(weight_diam)\n",
    "# plt.xlim(21000,21025)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
