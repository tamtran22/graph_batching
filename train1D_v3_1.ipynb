{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from data.dataset import OneDDatasetLoader, DatasetLoader\n",
    "from typing import List\n",
    "\n",
    "def train_eval_split(dataset : DatasetLoader, train_id : List, eval_id : List):\n",
    "    # Get batching id\n",
    "    if dataset._sub_dir == '/batched/':\n",
    "        batching_id = dataset.batching_id.numpy()\n",
    "        train_id = list(np.where(np.isin(batching_id, train_id) == True)[0])\n",
    "        eval_id = list(np.where(np.isin(batching_id, eval_id) == True)[0])\n",
    "    # Train dataset\n",
    "    train_dataset = [dataset[i] for i in train_id]\n",
    "    # Test dataset\n",
    "    eval_dataset = [dataset[i] for i in eval_id]\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_nodeattr_in',\n",
    "    sub_dir='/normalized/'\n",
    ")\n",
    "print('Dataset loaded.')\n",
    "\n",
    "# batched_dataset = dataset.batching(batch_size=None, batch_n_times=10, recursive=True,\n",
    "#                                     sub_dir='/batched/')\n",
    "# print('Dataset batching finished.')\n",
    "\n",
    "batched_dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_nodeattr_in',\n",
    "    sub_dir='/batched/'\n",
    ")\n",
    "\n",
    "train_dataset, eval_dataset = train_eval_split(\n",
    "    dataset=batched_dataset,\n",
    "    train_id=list(range(0,20)),\n",
    "    eval_id=list(range(20,40))\n",
    ")\n",
    "print('Train/eval spliting finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from networks.network_parc import PARC\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from networks.network_recurrent import objectview\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Model params\n",
    "args = objectview({\n",
    "    'n_fields' : 2,\n",
    "    'n_timesteps' : 1,\n",
    "    'n_hiddenfields' : 128,\n",
    "    'n_meshfields' : dataset[0].node_attr.size(1),\n",
    "    'timesteps' : 0.002,\n",
    "    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'lr' : 1e-7,\n",
    "    'weight_decay' : 1e-3,\n",
    "    'epoch' : 100,\n",
    "    'train_lambda' : 0.5\n",
    "})\n",
    "\n",
    "# Model initializing\n",
    "model = PARC(\n",
    "    n_fields=args.n_fields,\n",
    "    n_timesteps=args.n_timesteps,\n",
    "    n_hiddenfields=args.n_hiddenfields,\n",
    "    n_meshfields=args.n_meshfields\n",
    ")\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n",
    "# criterion = WeightedMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_derivative(F : torch.Tensor, dim : int = -1, delta_t : float = 1.) -> torch.Tensor:\n",
    "    _F = F.transpose(0, dim)\n",
    "    deriv_F = []\n",
    "    for i in range(1, _F.size(0)):\n",
    "        deriv_F_i = (_F[i] - _F[i-1]) / delta_t\n",
    "        deriv_F.append(deriv_F_i.unsqueeze(dim))\n",
    "    return torch.cat(deriv_F, dim=dim)\n",
    "\n",
    "# F = torch.cat([dataset[0].pressure.unsqueeze(-1),dataset[0].pressure.unsqueeze(-1)], dim=-1)\n",
    "# print(F.size())\n",
    "# deriv_F = cal_derivative(F, dim=1, delta_t=args.timesteps)\n",
    "# print(deriv_F.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train function v2\n",
    "def train(model, data, args):\n",
    "    n_time = data.pressure.size(1)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    mesh_features = data.node_attr.to(args.device)\n",
    "    F_initial = torch.cat([data.pressure[:,0].unsqueeze(1), data.velocity[:,0].unsqueeze(1)], dim=-1)\\\n",
    "                .to(args.device)\n",
    "    model.n_timesteps = n_time - 1\n",
    "\n",
    "    Fs, F_dots = model(F_initial, mesh_features, edge_index)\n",
    "\n",
    "    Fs_hat = torch.cat([data.pressure.unsqueeze(-1), data.velocity.unsqueeze(-1)], dim=-1)\\\n",
    "                .to(args.device)\n",
    "    \n",
    "    F_dots_hat = cal_derivative(Fs_hat, dim=1, delta_t=args.timesteps)\n",
    "\n",
    "    Fs_hat = Fs_hat[:,1:,:]\n",
    "\n",
    "    loss = (1.-args.train_lambda)*criterion(Fs_hat, Fs) + \\\n",
    "            args.train_lambda*criterion(F_dots_hat, F_dots)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Eval function\n",
    "def eval(model, data, args):\n",
    "    n_time = data.pressure.size(1)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    mesh_features = data.node_attr.to(args.device)\n",
    "    F_initial = torch.cat([data.pressure[:,0].unsqueeze(1), data.velocity[:,0].unsqueeze(1)], dim=-1)\\\n",
    "                .to(args.device)\n",
    "    model.n_timesteps = n_time - 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        Fs, F_dots = model(F_initial, mesh_features, edge_index)\n",
    "\n",
    "        Fs_hat = torch.cat([data.pressure.unsqueeze(-1), data.velocity.unsqueeze(-1)], dim=-1)\\\n",
    "                    .to(args.device)\n",
    "        \n",
    "        F_dots_hat = cal_derivative(Fs_hat, dim=1, delta_t=args.timesteps)\n",
    "\n",
    "        Fs_hat = Fs_hat[:,1:,:]\n",
    "\n",
    "        loss = (1.-args.train_lambda)*criterion(Fs_hat, Fs) + \\\n",
    "            args.train_lambda*criterion(F_dots_hat, F_dots)\n",
    "\n",
    "    return loss.item()\n",
    "# Training\n",
    "total_train_loss = []\n",
    "total_eval_loss = []\n",
    "for epoch in range(args.epoch):\n",
    "# for epoch in range(1):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = 0\n",
    "    for data in train_dataset:\n",
    "        train_loss += train(model=model, data=data, args=args)\n",
    "    train_loss /= len(train_dataset)\n",
    "    total_train_loss.append(train_loss)\n",
    "\n",
    "    eval_loss = 0\n",
    "    for data in eval_dataset:\n",
    "        eval_loss += eval(model=model, data=data, args=args)\n",
    "    eval_loss /= len(eval_dataset)\n",
    "    total_eval_loss.append(eval_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')\n",
    "    if (epoch+1) % 25 == 0:\n",
    "        torch.save(model.state_dict(), f'models/parc_v2_epoch{epoch+1}.pth')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/parc_v2_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct CFD output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct CFD\n",
    "def print_prediction(model, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initializing\n",
    "model = RecurrentMeshGraphNet(\n",
    "    input_dim_node = args.input_dim_node,\n",
    "    input_dim_edge = args.input_dim_edge,\n",
    "    output_dim_node = args.output_dim_node,\n",
    "    output_dim_edge = args.output_dim_edge,\n",
    "    hidden_dim = args.hidden_dim,\n",
    "    n_processors = args.n_processors\n",
    ")\n",
    "model = model.to(args.device)\n",
    "model.load_state_dict(torch.load('models/rmgn_v1_final.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction/ground truth\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison(model, data):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr\n",
    "\n",
    "    total_loss = 0\n",
    "    total_node_out = [data.pressure[:,0].unsqueeze(1)]\n",
    "    total_edge_out = [data.velocity[:,0].unsqueeze(1)]\n",
    "    for i in range(1, args.n_time):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "            _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "            _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity, _flowrate_bc], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "\n",
    "            loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_node_out.append(node_out.detach().cpu())\n",
    "            total_edge_out.append(edge_out.detach().cpu())\n",
    "    total_node_out = torch.cat(total_node_out, dim=1)\n",
    "    total_edge_out = torch.cat(total_edge_out, dim=1)\n",
    "    \n",
    "    # plot\n",
    "    node = 5\n",
    "    y_pred = total_edge_out[node].numpy()\n",
    "    y_true = data.velocity[node].numpy()\n",
    "    x = [i * 4.8 /200 for i in range(201)]\n",
    "    plt.plot(x, y_pred, c='red', label='RMGN')\n",
    "    plt.plot(x, y_true, c='blue', linestyle='dashdot', label='ground_truth')\n",
    "    # plt.ylim([-50,50])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Pressure', fontsize=20)\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return total_loss\n",
    "    \n",
    "mean, std = mean_std_dataset(_dataset, set_id=list(range(_dataset.len())))\n",
    "plot_comparison(model, normalize(_dataset[40], mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
