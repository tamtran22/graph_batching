{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from data.dataset import DatasetLoader\n",
    "from data.data import TorchGraphData\n",
    "from preprocessing.normalize import *\n",
    "import math\n",
    "\n",
    "_dataset = DatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_transformed'\n",
    ")\n",
    "\n",
    "def flowrate_bc_sin(flowrate, n_edge : int, \n",
    "                    n_time : int)->torch.Tensor:\n",
    "    _flowrate = []\n",
    "    T = 4.8 # seconds\n",
    "    for i in range(n_time):\n",
    "        t = i * T / (n_time - 1)\n",
    "        value = flowrate(t)\n",
    "        _flowrate.append(torch.full(size=(n_edge, 1), fill_value=value))\n",
    "    return torch.cat(_flowrate, dim=1)\n",
    "\n",
    "def normalize(data):\n",
    "    x = min_max_scaler(data.x, min=0, max=500)\n",
    "    edge_index = data.edge_index\n",
    "    edge_attr = min_max_scaler(data.edge_attr,\n",
    "                min=data.edge_attr.min(axis=0).values,\n",
    "                max=data.edge_attr.max(axis=0).values)\n",
    "    pressure = data.pressure * 1e-3\n",
    "    velocity = data.velocity * 1e-3\n",
    "    f = lambda t : (np.pi * 1e-3 / 4.8) * math.sin(2 * np.pi * t / 4.8)\n",
    "    flowrate_bc = flowrate_bc_sin(flowrate=f, n_edge=data.edge_attr.size(0),\\\n",
    "                                n_time=data.flowrate.size(1))\n",
    "    return TorchGraphData(x=x,edge_index=edge_index,edge_attr=edge_attr,\n",
    "                        pressure=pressure, velocity=velocity, \n",
    "                        flowrate_bc=flowrate_bc)\n",
    "\n",
    "dataset = []\n",
    "for i in range(_dataset.len()):\n",
    "    dataset.append(normalize(_dataset[i]))\n",
    "\n",
    "dataset[1].flowrate_bc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from networks.network_recurrent import RecurrentMeshGraphNet\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "from networks.network_recurrent import objectview\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Model params\n",
    "args = objectview({\n",
    "    'input_dim_node' : dataset[0].x.size(1),\n",
    "    'input_dim_edge' : dataset[0].edge_attr.size(1)+1,\n",
    "    'output_dim_node' : 1,\n",
    "    'output_dim_edge' : 1,\n",
    "    'hidden_dim' : 64,\n",
    "    'n_processors' : 10,\n",
    "    'n_time' : dataset[0].pressure.size(1),\n",
    "    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'lr' : 1e-7,\n",
    "    'weight_decay' : 5e-4,\n",
    "    'epoch' : 100,\n",
    "    'train_id' : list(range(0, 30)),\n",
    "    'eval_id' : list(range(30, 38))\n",
    "})\n",
    "\n",
    "# Model initializing\n",
    "model = RecurrentMeshGraphNet(\n",
    "    input_dim_node = args.input_dim_node,\n",
    "    input_dim_edge = args.input_dim_edge,\n",
    "    output_dim_node = args.output_dim_node,\n",
    "    output_dim_edge = args.output_dim_edge,\n",
    "    hidden_dim = args.hidden_dim,\n",
    "    n_processors = args.n_processors\n",
    ")\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function v1\n",
    "def train(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr\n",
    "\n",
    "    total_loss = 0\n",
    "    for i in range(1, args.n_time):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "        _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "        x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "        edge_attr = torch.cat([_edge_attr, _velocity], dim=1).to(args.device)\n",
    "        node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "        hidden = hidden.detach()\n",
    "\n",
    "        loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "        loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "# Eval function\n",
    "def eval(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr\n",
    "\n",
    "    total_loss = 0\n",
    "    for i in range(1, args.n_time):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "            _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "            loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "# Training\n",
    "for epoch in range(args.epoch):\n",
    "    train_loss = 0\n",
    "    for i in args.train_id:\n",
    "        train_loss += train(model=model, data=dataset[i], args=args)\n",
    "    train_loss /= len(args.train_id)\n",
    "\n",
    "    eval_loss = 0\n",
    "    for i in args.eval_id:\n",
    "        eval_loss += eval(model=model, data=dataset[i], args=args)\n",
    "    eval_loss /= len(args.eval_id)\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function v2\n",
    "def train(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x #.to(args.device)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr #.to(args.device)\n",
    "\n",
    "    total_loss = 0\n",
    "    for i in range(1, args.n_time):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "        x = torch.cat([_x], dim=1).to(args.device)\n",
    "        edge_attr = torch.cat([_edge_attr, _flowrate_bc], dim=1).to(args.device)\n",
    "        node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "        hidden = hidden.detach()\n",
    "\n",
    "        loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "        loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    return total_loss\n",
    "\n",
    "# Eval function\n",
    "def eval(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x #.to(args.device)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr #.to(args.device)\n",
    "\n",
    "    total_loss = 0\n",
    "    for i in range(1, args.n_time):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "            x = torch.cat([_x], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _flowrate_bc], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "            loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "    return total_loss\n",
    "# Training\n",
    "for epoch in range(args.epoch):\n",
    "    train_loss = 0\n",
    "    for i in args.train_id:\n",
    "        train_loss += train(model=model, data=dataset[i], args=args)\n",
    "    train_loss /= len(args.train_id)\n",
    "\n",
    "    eval_loss = 0\n",
    "    for i in args.eval_id:\n",
    "        eval_loss += eval(model=model, data=dataset[i], args=args)\n",
    "    eval_loss /= len(args.eval_id)\n",
    "\n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/rmgn_v2.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct CFD output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct CFD\n",
    "def print_prediction(model, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction/ground truth\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison(model, data):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr\n",
    "\n",
    "    total_loss = 0\n",
    "    total_node_out = [data.pressure[:,0].unsqueeze(1)]\n",
    "    total_edge_out = [data.velocity[:,0].unsqueeze(1)]\n",
    "    for i in range(1, args.n_time):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "            _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "            loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_node_out.append(node_out.detach().cpu())\n",
    "            total_edge_out.append(edge_out.detach().cpu())\n",
    "    total_node_out = torch.cat(total_node_out, dim=1)\n",
    "    total_edge_out = torch.cat(total_edge_out, dim=1)\n",
    "    \n",
    "    # plot\n",
    "    node = 50000\n",
    "    y_pred = total_node_out[node].numpy()\n",
    "    y_true = data.pressure[node].numpy()\n",
    "    x = [i * 4.8 /200 for i in range(201)]\n",
    "    plt.plot(x, y_pred, c='red', label='RMGN')\n",
    "    plt.plot(x, y_true, c='blue', linestyle='dashdot', label='ground_truth')\n",
    "    # plt.ylim([-50,50])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Pressure', fontsize=20)\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return total_loss\n",
    "    \n",
    "plot_comparison(model, dataset[40])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
