{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from data.dataset import DatasetLoader\n",
    "from data.data import TorchGraphData\n",
    "from preprocessing.normalize import *\n",
    "from preprocessing.batching_v2 import get_batch_graphs\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "def flowrate_bc_sin(flowrate, n_edge : int, \n",
    "                    n_time : int)->torch.Tensor:\n",
    "    _flowrate = []\n",
    "    T = 4.8 # seconds\n",
    "    for i in range(n_time):\n",
    "        t = i * T / (n_time - 1)\n",
    "        value = flowrate(t)\n",
    "        _flowrate.append(torch.full(size=(n_edge, 1), fill_value=value))\n",
    "    return torch.cat(_flowrate, dim=1)\n",
    "        \n",
    "\n",
    "def normalize(data, mean_ea, std_ea):\n",
    "    x = min_max_scaler(data.x, min=0, max=500)\n",
    "    edge_index = data.edge_index\n",
    "    edge_attr = standard_scaler(data.edge_attr,\n",
    "                mean=mean_ea,\n",
    "                std=std_ea)\n",
    "    pressure = data.pressure * 1e-3\n",
    "    velocity = data.velocity * 1e-3\n",
    "    f = lambda t : (np.pi * 1e0 / 4.8) * math.sin(2 * np.pi * t / 4.8)\n",
    "    flowrate_bc = flowrate_bc_sin(flowrate=f, n_edge=data.edge_attr.size(0),\\\n",
    "                                n_time=data.flowrate.size(1))\n",
    "    return TorchGraphData(x=x,edge_index=edge_index,edge_attr=edge_attr,\n",
    "                        pressure=pressure, velocity=velocity, \n",
    "                        flowrate_bc=flowrate_bc)\n",
    "\n",
    "def train_eval_split(dataset : DatasetLoader, train_id : List, eval_id : List,\n",
    "                    batch_size : int, batch_n_times : int, recursive : bool):\n",
    "    mean, std = mean_std_dataset(dataset, set_id=list(range(dataset.len())))\n",
    "    # Train dataset\n",
    "    train_dataset = []\n",
    "    for i in train_id:\n",
    "        data = normalize(dataset[i], mean, std)\n",
    "        train_dataset += get_batch_graphs(data=data, batch_size=batch_size,\n",
    "                        batch_n_times=batch_n_times, recursive=recursive)\n",
    "    # Test dataset\n",
    "    eval_dataset = []\n",
    "    for i in eval_id:\n",
    "        data = normalize(dataset[i], mean, std)\n",
    "        eval_dataset += get_batch_graphs(data=data, batch_size=batch_size,\n",
    "                        batch_n_times=batch_n_times, recursive=recursive)\n",
    "        # eval_dataset += [data]\n",
    "\n",
    "    return train_dataset, eval_dataset\n",
    "def mean_std_dataset(dataset : DatasetLoader, set_id : List, field : str = 'edge_attr'):\n",
    "    fields = []\n",
    "    for i in set_id:\n",
    "        fields.append(dataset[i]._store[field])\n",
    "    fields = torch.cat(fields, dim=0)\n",
    "    return fields.mean(axis=0), fields.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dataset = DatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_transformed'\n",
    ")\n",
    "\n",
    "train_dataset, eval_dataset = train_eval_split(\n",
    "    dataset=_dataset,\n",
    "    train_id=list(range(0, 20)),\n",
    "    eval_id=list(range(20, 40)),\n",
    "    batch_size=20000,\n",
    "    batch_n_times=20,\n",
    "    recursive=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize(DatasetLoader(root_dir='/data1/tam/downloaded_datasets_transformed')[0])\n",
    "pres = data.velocity.numpy().flatten() * 1e3\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(pres, bins=200)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from networks.network_recurrent import RecurrentMeshGraphNet\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "from networks.network_recurrent import objectview\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Model params\n",
    "args = objectview({\n",
    "    'input_dim_node' : _dataset[0].x.size(1)+1,\n",
    "    'input_dim_edge' : _dataset[0].edge_attr.size(1)+2,\n",
    "    'output_dim_node' : 1,\n",
    "    'output_dim_edge' : 1,\n",
    "    'hidden_dim' : 64,\n",
    "    'n_processors' : 10,\n",
    "    'n_time' : _dataset[0].pressure.size(1),\n",
    "    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'lr' : 1e-7,\n",
    "    'weight_decay' : 5e-3,\n",
    "    'epoch' : 100\n",
    "})\n",
    "\n",
    "# Model initializing\n",
    "model = RecurrentMeshGraphNet(\n",
    "    input_dim_node = args.input_dim_node,\n",
    "    input_dim_edge = args.input_dim_edge,\n",
    "    output_dim_node = args.output_dim_node,\n",
    "    output_dim_edge = args.output_dim_edge,\n",
    "    hidden_dim = args.hidden_dim,\n",
    "    n_processors = args.n_processors\n",
    ")\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "criterion = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train function v2\n",
    "def train(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x #.to(args.device)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr #.to(args.device)\n",
    "\n",
    "    _pressure = data.pressure[:,0].unsqueeze(1)\n",
    "    _velocity = data.velocity[:,0].unsqueeze(1)\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(1, data.number_of_timesteps):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "        # _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "        _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "        x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "        edge_attr = torch.cat([_edge_attr, _velocity, _flowrate_bc], dim=1).to(args.device)\n",
    "        node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "        hidden = hidden.detach()\n",
    "        _pressure = node_out.detach().cpu()\n",
    "        _velocity = edge_out.detach().cpu()\n",
    "\n",
    "        loss += criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "        loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Eval function\n",
    "def eval(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x #.to(args.device)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr #.to(args.device)\n",
    "\n",
    "    _pressure = data.pressure[:,0].unsqueeze(1)\n",
    "    _velocity = data.velocity[:,0].unsqueeze(1)\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(1, data.number_of_timesteps):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "            # _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "            _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity, _flowrate_bc], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "            _pressure = node_out.detach().cpu()\n",
    "            _velocity = edge_out.detach().cpu()\n",
    "\n",
    "            loss += criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "    return loss.item()\n",
    "# Training\n",
    "total_train_loss = []\n",
    "total_eval_loss = []\n",
    "for epoch in range(args.epoch):\n",
    "    train_loss = 0\n",
    "    for data in train_dataset:\n",
    "        train_loss += train(model=model, data=data, args=args)\n",
    "    train_loss /= len(train_dataset)\n",
    "    total_train_loss.append(train_loss)\n",
    "\n",
    "    eval_loss = 0\n",
    "    for data in eval_dataset:\n",
    "        eval_loss += eval(model=model, data=data, args=args)\n",
    "    eval_loss /= len(eval_dataset)\n",
    "    total_eval_loss.append(eval_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')\n",
    "    if epoch % 20 == 0:\n",
    "        torch.save(model.state_dict(), f'models/rmgnv1_epoch{epoch}.pth')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/rmgn_v2.pth')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct CFD output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct CFD\n",
    "def print_prediction(model, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initializing\n",
    "model = RecurrentMeshGraphNet(\n",
    "    input_dim_node = args.input_dim_node,\n",
    "    input_dim_edge = args.input_dim_edge,\n",
    "    output_dim_node = args.output_dim_node,\n",
    "    output_dim_edge = args.output_dim_edge,\n",
    "    hidden_dim = args.hidden_dim,\n",
    "    n_processors = args.n_processors\n",
    ")\n",
    "model = model.to(args.device)\n",
    "model.load_state_dict(torch.load('models/rmgn_v2.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction/ground truth\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison(model, data):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr\n",
    "\n",
    "    total_loss = 0\n",
    "    total_node_out = [data.pressure[:,0].unsqueeze(1)]\n",
    "    total_edge_out = [data.velocity[:,0].unsqueeze(1)]\n",
    "    for i in range(1, args.n_time):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "            _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "            _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity, _flowrate_bc], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "\n",
    "            loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_node_out.append(node_out.detach().cpu())\n",
    "            total_edge_out.append(edge_out.detach().cpu())\n",
    "    total_node_out = torch.cat(total_node_out, dim=1)\n",
    "    total_edge_out = torch.cat(total_edge_out, dim=1)\n",
    "    \n",
    "    # plot\n",
    "    node = 10000\n",
    "    y_pred = total_node_out[node].numpy()\n",
    "    y_true = data.pressure[node].numpy()\n",
    "    x = [i * 4.8 /200 for i in range(201)]\n",
    "    plt.plot(x, y_pred, c='red', label='RMGN')\n",
    "    plt.plot(x, y_true, c='blue', linestyle='dashdot', label='ground_truth')\n",
    "    # plt.ylim([-50,50])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Pressure', fontsize=20)\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return total_loss\n",
    "    \n",
    "mean, std = mean_std_dataset(_dataset, set_id=list(range(_dataset.len())))\n",
    "plot_comparison(model, normalize(_dataset[40], mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db637ecd267e8785137d274d569a1de945f5091a2538863d3f2fda8d3b4d9cce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
