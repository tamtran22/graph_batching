{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from data.dataset import OneDDatasetLoader, DatasetLoader\n",
    "from data.data import TorchGraphData\n",
    "from preprocessing.batching import merge_graphs\n",
    "import math\n",
    "from typing import List\n",
    "from networks.loss import WeightedMSELoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_split(dataset : DatasetLoader, train_id : List, eval_id : List):\n",
    "    # Get batching id\n",
    "    if dataset._sub_dir == '/batched/':\n",
    "        batching_id = dataset.batching_id.numpy()\n",
    "        train_id = list(np.where(np.isin(batching_id, train_id) == True)[0])\n",
    "        eval_id = list(np.where(np.isin(batching_id, eval_id) == True)[0])\n",
    "    # Train dataset\n",
    "    train_dataset = [dataset[i] for i in train_id]\n",
    "    # train_dataset = []\n",
    "    # for i in train_id:\n",
    "    #     train_dataset.append(dataset[i])\n",
    "    # Test dataset\n",
    "    eval_dataset = [dataset[i] for i in eval_id]\n",
    "    # eval_dataset = []\n",
    "    # for i in eval_id:\n",
    "    #     eval_dataset.append(dataset[i])\n",
    "    return train_dataset, eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded.\n",
      "Train/eval spliting finished.\n"
     ]
    }
   ],
   "source": [
    "dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_transformed'\n",
    ")\n",
    "print('Dataset loaded.')\n",
    "\n",
    "# batched_dataset = dataset.batching(batch_size=2000, batch_n_times=10, recursive=True,\n",
    "#                                     sub_dir='/batched/')\n",
    "# print('Dataset batching finished.')\n",
    "batched_dataset = OneDDatasetLoader(\n",
    "    root_dir='/data1/tam/downloaded_datasets_transformed',\n",
    "    sub_dir='/batched/'\n",
    ")\n",
    "\n",
    "train_dataset, eval_dataset = train_eval_split(\n",
    "    dataset=batched_dataset,\n",
    "    train_id=list(range(0,10)),\n",
    "    eval_id=list(range(20,30))\n",
    ")\n",
    "print('Train/eval spliting finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from networks.network_recurrent import RecurrentMeshGraphNet\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "from networks.network_recurrent import objectview\n",
    "CUDA_LAUNCH_BLOCKING=1\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Model params\n",
    "args = objectview({\n",
    "    'input_dim_node' : dataset[0].x.size(1)+1,\n",
    "    'input_dim_edge' : dataset[0].edge_attr.size(1)+1,\n",
    "    'output_dim_node' : 1,\n",
    "    'output_dim_edge' : 1,\n",
    "    'hidden_dim' : 128,\n",
    "    'n_processors' : 10,\n",
    "    'n_time' : dataset[0].pressure.size(1),\n",
    "    'device' : torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    'lr' : 1e-7,\n",
    "    'weight_decay' : 5e-2,\n",
    "    'epoch' : 100\n",
    "})\n",
    "\n",
    "# Model initializing\n",
    "model = RecurrentMeshGraphNet(\n",
    "    input_dim_node = args.input_dim_node,\n",
    "    input_dim_edge = args.input_dim_edge,\n",
    "    output_dim_node = args.output_dim_node,\n",
    "    output_dim_edge = args.output_dim_edge,\n",
    "    hidden_dim = args.hidden_dim,\n",
    "    n_processors = args.n_processors\n",
    ")\n",
    "model = model.to(args.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
    "# criterion = torch.nn.MSELoss()\n",
    "criterion = WeightedMSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train loss = 0.0013841526597373605; eval loss = 0.0005035101866362033\n",
      "Epoch 1: train loss = 0.00038627000389169553; eval loss = 0.0003126109806496477\n",
      "Epoch 2: train loss = 0.0002666036648889084; eval loss = 0.00023100943113789425\n",
      "Epoch 3: train loss = 0.00020453730427500162; eval loss = 0.00018261795115187727\n",
      "Epoch 4: train loss = 0.00016607997235481027; eval loss = 0.00015185794460417822\n",
      "Epoch 5: train loss = 0.00014122700471288826; eval loss = 0.00013132927890529896\n",
      "Epoch 6: train loss = 0.00012387648883088978; eval loss = 0.0001160209950857495\n",
      "Epoch 7: train loss = 0.00010991986062466729; eval loss = 0.00010314084390922475\n",
      "Epoch 8: train loss = 9.817626456682681e-05; eval loss = 9.25675553261021e-05\n",
      "Epoch 9: train loss = 8.860528448795484e-05; eval loss = 8.390208390792241e-05\n",
      "Epoch 10: train loss = 8.078897544310629e-05; eval loss = 7.683831562999176e-05\n",
      "Epoch 11: train loss = 7.417819941916234e-05; eval loss = 7.064798942765574e-05\n",
      "Epoch 12: train loss = 6.792521887224072e-05; eval loss = 6.46797642152744e-05\n",
      "Epoch 13: train loss = 6.116562008773051e-05; eval loss = 5.746005259122624e-05\n",
      "Epoch 14: train loss = 5.3633961660437506e-05; eval loss = 5.04128416962893e-05\n",
      "Epoch 15: train loss = 4.74679428970052e-05; eval loss = 4.4988781857829067e-05\n",
      "Epoch 16: train loss = 4.259252205871443e-05; eval loss = 4.0678944897206485e-05\n",
      "Epoch 17: train loss = 3.871062856381101e-05; eval loss = 3.711633401705659e-05\n",
      "Epoch 18: train loss = 3.5286604041539634e-05; eval loss = 3.409537978386151e-05\n",
      "Epoch 19: train loss = 3.274916051266747e-05; eval loss = 3.185805181307757e-05\n",
      "Epoch 20: train loss = 3.057429189964951e-05; eval loss = 2.9703917379871487e-05\n",
      "Epoch 21: train loss = 2.8453631651889397e-05; eval loss = 2.769600241901737e-05\n",
      "Epoch 22: train loss = 2.6691566074889077e-05; eval loss = 2.634517557366172e-05\n",
      "Epoch 23: train loss = 2.5550850198364236e-05; eval loss = 2.5287214845541335e-05\n",
      "Epoch 24: train loss = 2.4390054661339645e-05; eval loss = 2.4063520046941108e-05\n",
      "Epoch 25: train loss = 2.331276253057955e-05; eval loss = 2.315936079588806e-05\n",
      "Epoch 26: train loss = 2.2599345962660536e-05; eval loss = 2.2662243692455366e-05\n",
      "Epoch 27: train loss = 2.211845951735969e-05; eval loss = 2.2262783004049858e-05\n",
      "Epoch 28: train loss = 2.18502510882583e-05; eval loss = 2.2059807457026663e-05\n",
      "Epoch 29: train loss = 2.168051522107022e-05; eval loss = 2.188836800882748e-05\n",
      "Epoch 30: train loss = 2.1576538184344385e-05; eval loss = 2.1826910228286574e-05\n",
      "Epoch 31: train loss = 2.158479670891021e-05; eval loss = 2.181824784364256e-05\n",
      "Epoch 32: train loss = 2.1541508685868106e-05; eval loss = 2.178267234900079e-05\n",
      "Epoch 33: train loss = 2.150699821412498e-05; eval loss = 2.1726683604341674e-05\n",
      "Epoch 34: train loss = 2.14843687830189e-05; eval loss = 2.1757983971786712e-05\n",
      "Epoch 35: train loss = 2.1501937215084264e-05; eval loss = 2.1746771469896292e-05\n",
      "Epoch 36: train loss = 2.1603672072334792e-05; eval loss = 2.178970021663011e-05\n",
      "Epoch 37: train loss = 2.1613926818758714e-05; eval loss = 2.1736986307068783e-05\n",
      "Epoch 38: train loss = 2.16326708708039e-05; eval loss = 2.1729799407357647e-05\n",
      "Epoch 39: train loss = 2.1621776431363375e-05; eval loss = 2.1664962406161425e-05\n",
      "Epoch 40: train loss = 2.1642833662222856e-05; eval loss = 2.1643341408563796e-05\n",
      "Epoch 41: train loss = 2.167758065345246e-05; eval loss = 2.1612293687833454e-05\n",
      "Epoch 42: train loss = 2.170716766037722e-05; eval loss = 2.1579500714727203e-05\n",
      "Epoch 43: train loss = 2.1736998233906756e-05; eval loss = 2.15515998198735e-05\n",
      "Epoch 44: train loss = 2.1798494982803135e-05; eval loss = 2.1567370197034345e-05\n",
      "Epoch 45: train loss = 2.1930434781425386e-05; eval loss = 2.1648832412807185e-05\n",
      "Epoch 46: train loss = 2.2180329250236797e-05; eval loss = 2.1865764127165393e-05\n",
      "Epoch 47: train loss = 2.2571052711761176e-05; eval loss = 2.2235755197350096e-05\n",
      "Epoch 48: train loss = 2.3134525147680992e-05; eval loss = 2.2813039324634152e-05\n",
      "Epoch 49: train loss = 2.3869146546062833e-05; eval loss = 2.3337166265917603e-05\n",
      "Epoch 50: train loss = 2.454396663316639e-05; eval loss = 2.4106380155463426e-05\n",
      "Epoch 51: train loss = 2.5242019588157095e-05; eval loss = 2.4732271293287273e-05\n",
      "Epoch 52: train loss = 2.58771208095194e-05; eval loss = 2.5150653363894547e-05\n",
      "Epoch 53: train loss = 2.63816509267969e-05; eval loss = 2.5440512633994238e-05\n",
      "Epoch 54: train loss = 2.71648316557695e-05; eval loss = 2.6819788896925374e-05\n",
      "Epoch 55: train loss = 2.8713283708172834e-05; eval loss = 2.8315844027527417e-05\n",
      "Epoch 56: train loss = 3.0249029154868056e-05; eval loss = 2.9776583078011147e-05\n",
      "Epoch 57: train loss = 3.171846903360101e-05; eval loss = 3.117198105533317e-05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m train_dataset:\n\u001b[0;32m---> 82\u001b[0m     train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m train_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_dataset)\n\u001b[1;32m     84\u001b[0m total_train_loss\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[8], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, data, args)\u001b[0m\n\u001b[1;32m     28\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(edge_out, data\u001b[38;5;241m.\u001b[39mvelocity[:,i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice), edge_weight)\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# del x\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# del edge_attr\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# del node_out\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# del edge_out\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train function v2\n",
    "def train(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x #.to(args.device)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr #.to(args.device)\n",
    "\n",
    "    _pressure = data.pressure[:,0].unsqueeze(1)\n",
    "    _velocity = data.velocity[:,0].unsqueeze(1)\n",
    "\n",
    "    node_weight = data.node_weight.to(args.device)\n",
    "    edge_weight = data.edge_weight.to(args.device)\n",
    "    loss = 0\n",
    "    for i in range(1, data.number_of_timesteps):\n",
    "        # print(i)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "        edge_attr = torch.cat([_edge_attr, _velocity], dim=1).to(args.device)\n",
    "        node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "        hidden = hidden.detach()\n",
    "        _pressure = node_out.detach().cpu()\n",
    "        _velocity = edge_out.detach().cpu()\n",
    "\n",
    "        loss += criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device), node_weight)\n",
    "        loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device), edge_weight)\n",
    "\n",
    "        # del x\n",
    "        # del edge_attr\n",
    "        # del node_out\n",
    "        # del edge_out\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Eval function\n",
    "def eval(model, data, args):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x #.to(args.device)\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr #.to(args.device)\n",
    "\n",
    "    _pressure = data.pressure[:,0].unsqueeze(1)\n",
    "    _velocity = data.velocity[:,0].unsqueeze(1)\n",
    "\n",
    "    node_weight = data.node_weight.to(args.device)\n",
    "    edge_weight = data.edge_weight.to(args.device)\n",
    "\n",
    "    loss = 0\n",
    "    for i in range(1, data.number_of_timesteps):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "            _pressure = node_out.detach().cpu()\n",
    "            _velocity = edge_out.detach().cpu()\n",
    "\n",
    "            loss += criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device), node_weight)\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device), edge_weight)\n",
    "\n",
    "            # del x\n",
    "            # del edge_attr\n",
    "            # del node_out\n",
    "            # del edge_out\n",
    "\n",
    "    return loss.item()\n",
    "# Training\n",
    "total_train_loss = []\n",
    "total_eval_loss = []\n",
    "for epoch in range(args.epoch):\n",
    "# for epoch in range(1):\n",
    "    torch.cuda.empty_cache()\n",
    "    train_loss = 0\n",
    "    for data in train_dataset:\n",
    "        train_loss += train(model=model, data=data, args=args)\n",
    "    train_loss /= len(train_dataset)\n",
    "    total_train_loss.append(train_loss)\n",
    "\n",
    "    eval_loss = 0\n",
    "    for data in eval_dataset:\n",
    "        eval_loss += eval(model=model, data=data, args=args)\n",
    "    eval_loss /= len(eval_dataset)\n",
    "    total_eval_loss.append(eval_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}: train loss = {train_loss}; eval loss = {eval_loss}')\n",
    "    if (epoch+1) % 25 == 0:\n",
    "        torch.save(model.state_dict(), f'models/rmgn_v2_epoch{epoch+1}.pth')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'models/rmgn_v2_final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct CFD output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct CFD\n",
    "def print_prediction(model, data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model initializing\n",
    "model = RecurrentMeshGraphNet(\n",
    "    input_dim_node = args.input_dim_node,\n",
    "    input_dim_edge = args.input_dim_edge,\n",
    "    output_dim_node = args.output_dim_node,\n",
    "    output_dim_edge = args.output_dim_edge,\n",
    "    hidden_dim = args.hidden_dim,\n",
    "    n_processors = args.n_processors\n",
    ")\n",
    "model = model.to(args.device)\n",
    "model.load_state_dict(torch.load('models/rmgn_v1_final.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot prediction/ground truth\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_comparison(model, data):\n",
    "    n_edge = data.edge_attr.size(0)\n",
    "    hidden = torch.zeros(n_edge, args.hidden_dim).to(args.device)\n",
    "    _x = data.x\n",
    "    edge_index = data.edge_index.to(args.device)\n",
    "    _edge_attr = data.edge_attr\n",
    "\n",
    "    total_loss = 0\n",
    "    total_node_out = [data.pressure[:,0].unsqueeze(1)]\n",
    "    total_edge_out = [data.velocity[:,0].unsqueeze(1)]\n",
    "    for i in range(1, args.n_time):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            _pressure = data.pressure[:,i-1].unsqueeze(1)\n",
    "            _velocity = data.velocity[:,i-1].unsqueeze(1)\n",
    "            _flowrate_bc = data.flowrate_bc[:,i].unsqueeze(1)\n",
    "            x = torch.cat([_x, _pressure], dim=1).to(args.device)\n",
    "            edge_attr = torch.cat([_edge_attr, _velocity, _flowrate_bc], dim=1).to(args.device)\n",
    "            node_out, edge_out, hidden = model(x, edge_index, edge_attr, hidden)\n",
    "            hidden = hidden.detach()\n",
    "\n",
    "\n",
    "            loss = criterion(node_out, data.pressure[:,i].unsqueeze(1).float().to(args.device))\n",
    "            loss += criterion(edge_out, data.velocity[:,i].unsqueeze(1).float().to(args.device))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_node_out.append(node_out.detach().cpu())\n",
    "            total_edge_out.append(edge_out.detach().cpu())\n",
    "    total_node_out = torch.cat(total_node_out, dim=1)\n",
    "    total_edge_out = torch.cat(total_edge_out, dim=1)\n",
    "    \n",
    "    # plot\n",
    "    node = 5\n",
    "    y_pred = total_edge_out[node].numpy()\n",
    "    y_true = data.velocity[node].numpy()\n",
    "    x = [i * 4.8 /200 for i in range(201)]\n",
    "    plt.plot(x, y_pred, c='red', label='RMGN')\n",
    "    plt.plot(x, y_true, c='blue', linestyle='dashdot', label='ground_truth')\n",
    "    # plt.ylim([-50,50])\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Pressure', fontsize=20)\n",
    "    plt.xlabel('Time', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "    return total_loss\n",
    "    \n",
    "mean, std = mean_std_dataset(_dataset, set_id=list(range(_dataset.len())))\n",
    "plot_comparison(model, normalize(_dataset[40], mean, std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
